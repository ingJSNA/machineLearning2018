{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Quiz 3\n",
    "# Machine Learning 2018-1\n",
    "\n",
    "\n",
    "Keep saving your notebook to guarantee that you don't loose your work. Whenever the end of the quiz is announced save the current version. \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (2.0)\n",
    "The following code implements a feed-forward neural network with one hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def predict(w, x):\n",
    "    z = np.zeros((3,))\n",
    "    z[2] = relu(np.dot(x,w[6:8]) + w[8])\n",
    "    z[1] = relu(np.dot(x,w[3:5]) + w[5])\n",
    "    z[0] = sigmoid(np.dot(z[1:3], w[0:2]) + w[2])\n",
    "    return z[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a weight vector such that the neural network calculates the negated XOR function:\n",
    "    \n",
    "$$f(x,y)=\\neg(x\\textrm{ xor }y)$$\n",
    "\n",
    "Use the following variable to put the weight vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.zeros(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x,y) = \\neg(x\\textrm{ xor }y)  = (x \\textrm{ and } y) \\textrm{ or } (\\neg x \\textrm{ and } \\neg y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 1 == 1.0\n",
      "\tand 0.0\n",
      "\tnot x and not y 2.0\n",
      "\tor 0.9996646498695336\n",
      "[0, 1] 0 == 0.00034\n",
      "\tand 0.0\n",
      "\tnot x and not y 0.0\n",
      "\tor 0.0003353501304664781\n",
      "[1, 0] 0 == 0.00034\n",
      "\tand 0.0\n",
      "\tnot x and not y 0.0\n",
      "\tor 0.0003353501304664781\n",
      "[1, 1] 1 == 1.0\n",
      "\tand 2.0\n",
      "\tnot x and not y 0.0\n",
      "\tor 0.9996646498695336\n",
      "error 0.03%\n"
     ]
    }
   ],
   "source": [
    "#             2           5          8\n",
    "W1 = [32, 32, -8,   -1, -1, 0.5,   1, 1, -1.5]\n",
    "\n",
    "W1 = [8, 8, -8,   -4, -4, 2,   2, 2, -2]\n",
    "\n",
    "X = [[0, 0],\n",
    "     [0, 1],\n",
    "     [1, 0],\n",
    "     [1, 1]]\n",
    "Y = [1, 0, 0 ,1]\n",
    "\n",
    "error=0\n",
    "for i, x in enumerate(X):\n",
    "    y = Y[i]\n",
    "    p = predict(W1, x)\n",
    "    error += np.abs(y-p) \n",
    "    print(x, \"{} == {:.2}\".format(y, p))\n",
    "    w = W1\n",
    "    z = np.zeros((3,))\n",
    "    z[2] = relu(np.dot(x,w[6:8]) + w[8])\n",
    "    z[1] = relu(np.dot(x,w[3:5]) + w[5])\n",
    "    z[0] = sigmoid(np.dot(z[1:3], w[0:2]) + w[2])\n",
    "    print(\"\\tand\", z[2])\n",
    "    print(\"\\tnot x and not y\", z[1])\n",
    "    print(\"\\tor\", z[0])\n",
    "error = error/len(Y)\n",
    "print(\"error\", \"{:.2%}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (3.0)\n",
    "\n",
    "Assuming the following loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w, x, y):\n",
    "    return (y - predict(w, x))**2/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that uses backpropagation to calculate:\n",
    "    \n",
    "$$\\frac{\\partial E(w, x, y)}{\\partial w_0}$$\n",
    "\n",
    "Where $E$ is the loss function defined before. Explicitely write the expressions that you derive:\n",
    "\n",
    "$$\\delta_0 = $$\n",
    "\n",
    "$$\\frac{\\partial E(w, x, y)}{\\partial w_0} = $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\delta_0 = \\frac{\\delta E_l}{\\delta a_0} = (z_0 - y) \\sigma'(z0) $$\n",
    "\n",
    "$$\\frac{\\partial E(w, x, y)}{\\partial w_0} = \\delta_0 z_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34147939 -0.07596938  1.92849467  1.38126845 -0.7580072   1.63895875\n",
      "  1.21757044 -1.37304186  1.39475178] [-0.6306162  -0.27112827] [-1.06945823] 0.8988935482934953\n",
      "[0.39393141] [0.17413764]\n",
      "0.2197937756215101\n",
      "Fail\n",
      "[-1.83547043 -1.14791197 -0.3223096  -0.56288227  0.39647265  0.25825578\n",
      "  2.17860247 -3.37189348 -0.6771984 ] [1.38653727 0.56156523] [-0.2219796] 0.30177839241137655\n",
      "[0.] [0.]\n",
      "0.0\n",
      "[ 1.1987156   1.51255919  0.81041975 -0.94819471  0.26066137 -0.08213504\n",
      " -1.37186184 -1.07579719 -1.26908714] [ 1.15524825 -1.65500813] [0.06972757] 0.6921989439230762\n",
      "[0.] [0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def dE_dw0(w, x, y):\n",
    "    # your code here\n",
    "    z0 = predict(w,x)\n",
    "    \n",
    "    l3_error = z0 - y\n",
    "    l3_delta = l3_error * sigmoid(z0) * (1-sigmoid(z0))\n",
    "    \n",
    "    z = np.zeros((3,))\n",
    "    z[2] = relu(np.dot(x,w[6:8]) + w[8])\n",
    "    z[1] = relu(np.dot(x,w[3:5]) + w[5])\n",
    "    a0 = z[1]\n",
    "    z[0] = sigmoid(np.dot(z[1:3], w[0:2]) + w[2])\n",
    "    \n",
    "    e = l3_delta * a0\n",
    "    \n",
    "    return e\n",
    "\n",
    "\n",
    "# Numerical estimation\n",
    "def num_dE_dw0(w, x, y, epsilon):\n",
    "    delta = np.zeros(len(w))\n",
    "    delta[0] = epsilon\n",
    "    de = (loss(w + delta, x, y) - loss(w - delta, x, y)) / (2 * epsilon)\n",
    "    return de\n",
    "\n",
    "for i in range(3):\n",
    "    tw = np.random.randn(9)\n",
    "    tx = np.random.randn(2)\n",
    "    ty = np.random.randn(1)\n",
    "    print(tw, tx, ty, predict(tw, tx))\n",
    "    epsilon = 0.0001\n",
    "    dE = dE_dw0(tw, tx,ty)\n",
    "    print(dE, num_dE_dw0(tw, tx, ty, epsilon))\n",
    "    diff = np.linalg.norm(dE - num_dE_dw0(tw, tx, ty, epsilon))\n",
    "    print(diff)\n",
    "    if diff > epsilon:\n",
    "        print(\"Fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grader\n",
    "Run the following code to grade your exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  20 / 50\n"
     ]
    }
   ],
   "source": [
    "def approx_equal(val1, val2):\n",
    "    return abs(val1-val2) <= 0.00001\n",
    "\n",
    "def test_dict(test, answer):\n",
    "    if sorted(test.keys()) != sorted(answer.keys()): return False\n",
    "    for k,v in test.items():\n",
    "        if not approx_equal(v,answer[k]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def test1():\n",
    "    epsilon = 0.001\n",
    "    X = [[0, 0],\n",
    "     [0, 1],\n",
    "     [1, 0],\n",
    "     [1, 1]]\n",
    "    Y = [1, 0, 0 ,1]\n",
    "    for i, x in enumerate(X):\n",
    "        if np.abs(predict(W1, x) - Y[i]) > epsilon: \n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def num_dE_dw0(w, x, y, epsilon):\n",
    "    delta = np.zeros(len(w))\n",
    "    delta[0] = epsilon\n",
    "    de = (loss(w + delta, x, y) - loss(w - delta, x, y)) / (2 * epsilon)\n",
    "    return de\n",
    "\n",
    "def test2():\n",
    "    num_tests = 100\n",
    "    epsilon = 0.0001\n",
    "    for i in range(num_tests):\n",
    "        tw = np.random.randn(9)\n",
    "        tx = np.random.randn(2)\n",
    "        ty = np.random.randn(1)\n",
    "        if np.linalg.norm(dE_dw0(tw, tx,ty) - num_dE_dw0(tw, tx, ty, epsilon)) > epsilon:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    score = 0 \n",
    "    for test, sc in [(test1, 20), (test2, 30)]:\n",
    "        if test():\n",
    "            score += sc\n",
    "    return score\n",
    "\n",
    "print(\"Score: \", evaluate(), \"/ 50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
