{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Quiz 3\n",
    "# Machine Learning 2018-1\n",
    "\n",
    "\n",
    "Keep saving your notebook to guarantee that you don't loose your work. Whenever the end of the quiz is announced save the current version. \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (2.0)\n",
    "The following code implements a feed-forward neural network with one hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def predict(w, x):\n",
    "    z = np.zeros((3,))\n",
    "    z[2] = relu(np.dot(x,w[6:8]) + w[8])\n",
    "    z[1] = relu(np.dot(x,w[3:5]) + w[5])\n",
    "    z[0] = sigmoid(np.dot(z[1:3], w[0:2]) + w[2])\n",
    "    return z[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a weight vector such that the neural network calculates the negated XOR function:\n",
    "    \n",
    "$$f(x,y)=\\neg(x\\textrm{ xor }y)$$\n",
    "\n",
    "Use the following variable to put the weight vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.zeros(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x,y) = \\neg(x\\textrm{ xor }y)  = (x \\textrm{ and } y) \\textrm{ or } (\\neg x \\textrm{ and } \\neg y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 1 == 1.0\n",
      "\tand 0.0\n",
      "\tnot x and not y 2.0\n",
      "\tor 0.9996646498695336\n",
      "[0, 1] 0 == 0.00034\n",
      "\tand 0.0\n",
      "\tnot x and not y 0.0\n",
      "\tor 0.0003353501304664781\n",
      "[1, 0] 0 == 0.00034\n",
      "\tand 0.0\n",
      "\tnot x and not y 0.0\n",
      "\tor 0.0003353501304664781\n",
      "[1, 1] 1 == 1.0\n",
      "\tand 2.0\n",
      "\tnot x and not y 0.0\n",
      "\tor 0.9996646498695336\n",
      "error 0.03%\n"
     ]
    }
   ],
   "source": [
    "#             2           5          8\n",
    "W1 = [32, 32, -8,   -1, -1, 0.5,   1, 1, -1.5]\n",
    "\n",
    "W1 = [8, 8, -8,   -4, -4, 2,   2, 2, -2]\n",
    "\n",
    "X = [[0, 0],\n",
    "     [0, 1],\n",
    "     [1, 0],\n",
    "     [1, 1]]\n",
    "Y = [1, 0, 0 ,1]\n",
    "\n",
    "error=0\n",
    "for i, x in enumerate(X):\n",
    "    y = Y[i]\n",
    "    p = predict(W1, x)\n",
    "    error += np.abs(y-p) \n",
    "    print(x, \"{} == {:.2}\".format(y, p))\n",
    "    w = W1\n",
    "    z = np.zeros((3,))\n",
    "    z[2] = relu(np.dot(x,w[6:8]) + w[8])\n",
    "    z[1] = relu(np.dot(x,w[3:5]) + w[5])\n",
    "    z[0] = sigmoid(np.dot(z[1:3], w[0:2]) + w[2])\n",
    "    print(\"\\tand\", z[2])\n",
    "    print(\"\\tnot x and not y\", z[1])\n",
    "    print(\"\\tor\", z[0])\n",
    "error = error/len(Y)\n",
    "print(\"error\", \"{:.2%}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (3.0)\n",
    "\n",
    "Assuming the following loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w, x, y):\n",
    "    return (y - predict(w, x))**2/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that uses backpropagation to calculate:\n",
    "    \n",
    "$$\\frac{\\partial E(w, x, y)}{\\partial w_0}$$\n",
    "\n",
    "Where $E$ is the loss function defined before. Explicitely write the expressions that you derive:\n",
    "\n",
    "$$\\delta_0 =$$\n",
    "\n",
    "$$\\frac{\\partial E(w, x, y)}{\\partial w_0} = $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dE_dw0(w, x, y):\n",
    "    # your code here\n",
    "    d0 = y - predict(w,x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grader\n",
    "Run the following code to grade your exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  20 / 50\n"
     ]
    }
   ],
   "source": [
    "def approx_equal(val1, val2):\n",
    "    return abs(val1-val2) <= 0.00001\n",
    "\n",
    "def test_dict(test, answer):\n",
    "    if sorted(test.keys()) != sorted(answer.keys()): return False\n",
    "    for k,v in test.items():\n",
    "        if not approx_equal(v,answer[k]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def test1():\n",
    "    epsilon = 0.001\n",
    "    X = [[0, 0],\n",
    "     [0, 1],\n",
    "     [1, 0],\n",
    "     [1, 1]]\n",
    "    Y = [1, 0, 0 ,1]\n",
    "    for i, x in enumerate(X):\n",
    "        if np.abs(predict(W1, x) - Y[i]) > epsilon: \n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def num_dE_dw0(w, x, y, epsilon):\n",
    "    delta = np.zeros(len(w))\n",
    "    delta[0] = epsilon\n",
    "    de = (loss(w + delta, x, y) - loss(w - delta, x, y)) / (2 * epsilon)\n",
    "    return de\n",
    "\n",
    "def test2():\n",
    "    num_tests = 100\n",
    "    epsilon = 0.0001\n",
    "    for i in range(num_tests):\n",
    "        tw = np.random.randn(9)\n",
    "        tx = np.random.randn(2)\n",
    "        ty = np.random.randn(1)\n",
    "        if np.linalg.norm(dE_dw0(tw, tx,ty) - num_dE_dw0(tw, tx, ty, epsilon)) > epsilon:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    score = 0 \n",
    "    for test, sc in [(test1, 20), (test2, 30)]:\n",
    "        if test():\n",
    "            score += sc\n",
    "    return score\n",
    "\n",
    "print(\"Score: \", evaluate(), \"/ 50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
